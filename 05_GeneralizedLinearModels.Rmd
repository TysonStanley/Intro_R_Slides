---
title: "Chapter 5: Generalized Linear Modeling"
author: "Tyson S. Barrett"
date: "Summer 2017"
institute: "Utah State University"
fontsize: 10pt
output:
  beamer_presentation:
    theme: "metropolis"
    toc: true
    fig_width: 4.5
    fig_height: 3.5
    fig_caption: true
    df_print: default
    keep_tex: true
    incremental: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
## Run but not shown
## Getting data ready for the examples
library(foreign)
library(furniture)
library(tidyverse)
dem_df <- read.xport("~/Box Sync/GitHub/blog_rstats/assets/Data/NHANES_demographics_11.xpt")
med_df <- read.xport("~/Box Sync/GitHub/blog_rstats/assets/Data/NHANES_MedHeath_11.xpt")
men_df <- read.xport("~/Box Sync/GitHub/blog_rstats/assets/Data/NHANES_MentHealth_11.xpt")
act_df <- read.xport("~/Box Sync/GitHub/blog_rstats/assets/Data/NHANES_PhysActivity_11.xpt")
names(dem_df) <- tolower(names(dem_df))
names(med_df) <- tolower(names(med_df))
names(men_df) <- tolower(names(men_df))
names(act_df) <- tolower(names(act_df))
df <- dem_df %>%
  full_join(med_df, by="seqn") %>%
  full_join(men_df, by="seqn") %>%
  full_join(act_df, by="seqn") %>%
  mutate(marriage = factor(washer(dmdmartl, 77, 99))) %>%
  filter(complete.cases(marriage)) %>%
  mutate(race = factor(ridreth1, 
                       labels=c("MexicanAmerican", "OtherHispanic", 
                                "White", "Black", "Other"))) %>%
  mutate(famsize = as.numeric(washer(dmdfmsiz, 7,9))) %>%
  mutate(dpq010 = washer(dpq010, 7,9),
         dpq020 = washer(dpq020, 7,9),
         dpq030 = washer(dpq030, 7,9),
         dpq040 = washer(dpq040, 7,9),
         dpq050 = washer(dpq050, 7,9),
         dpq060 = washer(dpq060, 7,9),
         dpq070 = washer(dpq070, 7,9),
         dpq080 = washer(dpq080, 7,9),
         dpq090 = washer(dpq090, 7,9),
         dpq100 = washer(dpq100, 7,9)) %>%
  mutate(dep = dpq010 + dpq020 + dpq030 + dpq040 + dpq050 +
               dpq060 + dpq070 + dpq080 + dpq090) %>%
  mutate(dep2 = factor(ifelse(dep >= 10, 1,
                       ifelse(dep < 10, 0, NA))))
df <- df %>%
  mutate(asthma = washer(mcq010, 9, 7),
         asthma = factor(washer(asthma, 2, value = 0),
                         labels = c("No Asthma", "Asthma"))) %>%
  mutate(sed = washer(pad680, 9999, 7777)) %>%
  mutate(cluster = sdmvstra - 89) %>%
  filter(complete.cases(asthma) & complete.cases(dep2)) 
```


# Introduction

## Good Quote

\Large

> "You must stick to your conviction, but be ready to abandon your assumptions."
>
> --- Dennis Waitley

## GLMs

\large
Generalized Linear Models (GLMs):

1. Are extensions of linear regression to areas where assumptions of normality and homoskedasticity do not hold
2. There are several versions of GLM's, each for different types and distributions of outcomes. 

We are going to go through several of the most common GLMs. 

## Types

\large 

We discuss:

1. Logistic Regression
2. Poisson Regression
3. GLM with Gamma distribution
4. Negative binomial
5. Beta Regression

# Logistic Regression

## Logistic Regression

\large
For binary outcomes (e.g., yes or no, correct or incorrect, sick or healthy)

$$
logit(Y) = \beta_0 + \beta_1 X_1 + ... + \epsilon
$$

where $logit(Y) = ln\Big(\frac{Prob(Y = 1)}{1 - Prob(Y = 1)}\Big)$

## Prep Data
\small
```{r}
## First creating binary depression variable
## Use mutate()
df <- df %>%
  mutate(dep = dpq010 + dpq020 + dpq030 + dpq040 + dpq050 +
               dpq060 + dpq070 + dpq080 + dpq090) %>%
  mutate(dep2 = ifelse(dep >= 10, 1,
                ifelse(dep < 10, 0, NA)))
## Fix some placeholders
df <- df %>%
  mutate(asthma = washer(mcq010, 9),
         asthma = washer(asthma, 2, value = 0)) %>%
  mutate(sed = washer(pad680, 9999, 7777))
```
\large
Note:

1. IF depression $\geq 10$ then dep2 is 1, 
2. IF dpression $< 10$, then dep2 is 0, 
3. ELSE dep2 is NA.


## Running Logistic Regression

\Large

- $\beta$s are in "log-odds" 
- $e^{\beta}$ is an "odds ratio" 

In `R`, this is simple.

## Running Logistic Regression

\large

```{r, message=FALSE, warning=FALSE,eval=FALSE}
l_fit <- glm(dep2 ~ asthma + sed + race + famsize,
             data = df,
             family = "binomial")
summary(l_fit)
```

## Running Logistic Regression

\small
```{r, message=FALSE, warning=FALSE,echo=FALSE}
l_fit <- glm(dep2 ~ asthma + sed + race + famsize,
             data = df,
             family = "binomial")
summary(l_fit)
```
\Large

## Output of Logistic Regression

\large

We used `glm()` (stands for generalized linear model)

- The key to making it logistic, since you can use `glm()` for a linear model using maximum likelihood instead of `lm()` with least squares, is `family = "binomial"`
- Default link in "binomial" is `logit`.
- Can also do `probit` to use probit regression.

# Poisson Regression

## Poisson Regression

\large

Again, use the `glm()` function. 

- The difference here is we will be using an outcome that is a count variable. 
   - For example, the sedentary variable (`sed`) that we have in `df` is a count of the minutes of sedentary activity.

## Running Poisson Regression

\large

```{r, message=FALSE, warning=FALSE,eval=FALSE}
p_fit <- glm(sed ~ asthma + race + famsize,
             data = df,
             family = "poisson")
summary(p_fit)
```


## Running Poisson Regression
\tiny
```{r, message=FALSE, warning=FALSE,echo=FALSE}
p_fit <- glm(sed ~ asthma + race + famsize,
             data = df,
             family = "poisson")
summary(p_fit)
```


## Running Poisson Regression

\small
Sedentary may be over-dispersed:
```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.height = 3, fig.width=4}
qplot(df$sed, alpha = .75, binwidth = 75) + 
  theme_bw() +
  labs(x = "Minutes of Sedentary Behavior") +
  scale_alpha(guide=FALSE)
```

## Running Poisson Regression
\Large
and so other methods related to poisson may be necessary. 

- See gamma, hurdle models, and negative binomial models next


## Gamma

\Large

* very similar to poisson but does not require integers and can handle more dispersion. 
* the outcome must have values $> 0$.

## Gamma

\small
```{r, message=FALSE, warning=FALSE, eval=FALSE}
## Adjust sed
df$sed_gamma <- df$sed + .01
g_fit <- glm(sed_gamma ~ asthma + race + famsize,
             data = df,
             family = "Gamma")
summary(g_fit)
```

## Gamma

\small
```{r, message=FALSE, warning=FALSE, echo=FALSE}
## Adjust sed
df$sed_gamma <- df$sed + .01
g_fit <- glm(sed_gamma ~ asthma + race + famsize,
             data = df,
             family = "Gamma")
summary(g_fit)
```
\Large

## Two-Part or Hurdle Models

\large

- Use the `pscl` package to run a hurdle model. 
- These models are built for situations where there is a count variable with many zeros ("zero-inflated"). 
- The hurdle model makes slightly different assumptions regarding the zeros than the pure negative binomial that we present next. 
- The hurdle consists of two models: one for whether the person had a zero or more (binomial) and if more than zero, how many (poisson).

To run a hurdle model, we are going to make a sedentary variable with many more zeros to illustrate and then we will run a hurdle model.

## Two-Part or Hurdle Models

\small
```{r, message=FALSE, warning=FALSE, eval=FALSE}
## Zero inflated sedentary (don't worry too much about the specifics)
df$sed_zero <- ifelse(sample(1:100, 
                             size = length(df$sed), 
                             replace=TRUE) %in% c(5,10,11,20:25), 0, 
                      df$sed)
## Hurdle model
library(pscl)
h_fit = hurdle(sed_zero ~ asthma + race + famsize,
               data = df)
summary(h_fit)
```
\normalsize

## Two-Part or Hurdle Models

\tiny
```{r, message=FALSE, warning=FALSE, echo=FALSE}
## Zero inflated sedentary (don't worry too much about the specifics)
df$sed_zero <- ifelse(sample(1:100, 
                             size = length(df$sed), 
                             replace=TRUE) %in% c(5,10,11,20:25), 0, 
                      df$sed)
## Hurdle model
library(pscl)
h_fit = hurdle(sed_zero ~ asthma + race + famsize,
               data = df)
summary(h_fit)
```
\Large

## Hurdle Models

\large

Notice that the output has two parts: 

1. "Count model coefficients (truncated poisson with log link):" and 
2. "Zero hurdle model coefficients (binomial with logit link):". 

Together they tell us about the relationship between the predictors and a count variable with many zeros.


## Negative Binomial

\large

- negative binomial is also for zero-inflated count variables.
- It makes slightly different assumptions than the hurdle and doesn't use a two-part approach. 
- Use the `MASS` package and the `glm.nb()` function.

\small
```{r, eval=FALSE, warning=FALSE, message=FALSE,eval=FALSE}
library(MASS)
fit_nb <- glm.nb(sed_zero ~ asthma + race + famsize,
                 data = df)
summary(fit_nb)
```


## Negative Binomial
\small
```{r, eval=FALSE, warning=FALSE, message=FALSE, echo=FALSE}
library(MASS)
fit_nb <- glm.nb(sed_zero ~ asthma + race + famsize,
                 data = df)
summary(fit_nb)
```
\Large

Note that this model is not really appropriate because our data is somewhat contrived. 


# Beta Regression

## Beta Regression

\large

- For outcomes that are bound between a lower and upper bound
   - For example, if we are looking at test scores that are bound between 0 and 100. 
- It is a very flexible method and allows for some extra analysis regarding the variation. 

## Running Beta Regression

- Use the `betareg` package.
- But first, we are going to reach a little and create a ficticiously bound variable in the data set.
```{r, message=FALSE, warning=FALSE, eval=FALSE}
## Variable bound between 0 and 1
df$beta_var <- sample(seq(.05, .99, by = .01), 
                      size = length(df$asthma),
                      replace = TRUE)
library(betareg)
fit_beta <- betareg(beta_var ~ asthma + race + famsize,
                    data = df)
summary(fit_beta)
```

## Running Beta Regression

\tiny
```{r, message=FALSE, warning=FALSE, echo=FALSE}
## Variable bound between 0 and 1
df$beta_var <- sample(seq(.05, .99, by = .01), 
                      size = length(df$asthma),
                      replace = TRUE)
library(betareg)
fit_beta <- betareg(beta_var ~ asthma + race + famsize,
                    data = df)
summary(fit_beta)
```
\Large

## Beta Regression

\large

- The output provides coefficients and the "Phi" coefficients.
- Both are important parts of using beta regression but we are not going to discuss it here. 

# Conclusions
## Conclusions

\large

There are many resources available to learn more about each of these GLM's. 

As for now, we are going to move on to more complex modeling where there are clustering or repeated measures in the data. 

## Conclusions

\large

One of the great things about `R` is that most modeling is very similar to the basic `lm()` function. 

- In all of these GLM's the arguments are nearly all the same: 
    - a formula, 
    - the data, and 
    - family of model. 
- As you'll see for Multilevel and Other Models chapters, this does not change much. 
- Having a good start with basic models and GLM's gets you ready for nearly every other modeling type in `R`.

